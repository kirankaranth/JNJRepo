from DatabaseLibrary import DatabaseLibrary
from sqlalchemy import MetaData, Table, text, create_engine, join, inspect
from sqlalchemy.orm import sessionmaker
from tabulate import tabulate
from robot.api import logger
from sqlalchemy.engine import reflection
from pyspark import SparkContext
from pyspark.sql import SparkSession
import traceback  # only used for connection
import re
import os


class DatabricksQuery(DatabaseLibrary):
    def __init__(self):
        self.table_model = None
        self.column_names = []
        self.conn = None
        self.meta = None
        self.engine = None
        self.session = None
        self.query_list = []

    def connect_databricks(self, region, token, database, http_path):
        """
        Creates engine by connecting to database
        :type http_path: http path
        :param token: access token generated by databricks admin
        :param database:  database which you want to access
        :param region: physical region of the server
        :return: sets engine
        """
        # Azure Databricks with token
        # provide token, region for url, database name, http_path (with cluster name)
        logger.console(region)
        try:
            dbfs_engine = create_engine(
                "databricks+pyhive://token:"
                + token
                + "@"
                + region
                + ".azuredatabricks.net:443/"
                + database,
                connect_args={"http_path": http_path},
                echo=True,
            )
            self._set_metadata_databricks(dbfs_engine)
            Session = sessionmaker(bind=dbfs_engine)
            self.session = Session()
            self.engine = dbfs_engine
            self.conn = dbfs_engine.connect()
            print(
                "successfully connected to database " + database + " url: " + http_path
            )
        except Exception as e:
            traceback.print_exc()
            raise e

    def disconnect_databricks(self):
        """
        Disconnects databricks connection if it is connected.
        """
        if self.conn:
            self.conn.close()
            self.conn = None
            self.meta = None
            self.engine = None
            self.session = None
        print("successfully disconected from database ")

    def _set_metadata_databricks(self, engine):
        """
        Initialises metadata and binds it to the engine for databricks (do not reflect tables)
        :param engine:
        :return: sets metadata
        """
        self.meta = MetaData(bind=engine)

    def _set_table(self, table_name):
        """
        :param table_name: takes table name from robot test and sets it as the current table object
        :return: SQLAlchemy Table object
        """
        table_and_schema = table_name.split(".")
        try:
            return Table(
                table_and_schema[1],
                self.meta,
                autoload=True,
                autoload_with=self.engine,
                schema=table_and_schema[0],
            )
        except Exception as e:
            logger.console(e)

    def add_result_to_report(self, result):
        """
        Keyword used to add a result to the list for the report
        :param result: ${result} from query passed in from robot keyword
        """
        self.query_list.append(result)

    def write_to_file(self, robot_test_tag):
        """
        Create report that prints queries used for a robot test in respective order of execution
        Regular expression checks the integrity of the robot tag i.e (4characters-5digits)
        :param robot_test_tag:  the tag of the robot test you wish to create a file for
        """
        try:
            if re.search("^[\\w]{4}-[\\d]{4,5}", robot_test_tag):  # pattern match check
                print("robot_test_tag = " + robot_test_tag)
                search_result = re.search("^[\\w]{4}-[\\d]{4,5}", robot_test_tag)
                span_value_int = int("".join(map(str, search_result.span(0))))
                if len(robot_test_tag) >= 9:
                    story_num = robot_test_tag[
                        :span_value_int
                    ]  # slice first 9 or 10 characters i.e. the story number of robot tag
                else:
                    story_num = robot_test_tag
                #filename = f"""Tests{os.path.sep}Reports{os.path.sep}{story_num}{os.path.sep}report-{robot_test_tag}.txt"""
                filename = f"""Output{os.path.sep}report-{robot_test_tag}.txt"""
                os.makedirs(
                    os.path.dirname(filename), exist_ok=True
                )  # check if directory exists and create it if not
                f = open(filename, "w", encoding="utf-8")
                f.write(
                    tabulate([[f"Robot Test: {robot_test_tag}\n"]], tablefmt="grid")
                )
                f.write("\n")
                for query_string in self.query_list:
                    f.write(f"{query_string}\n")
                f.close()
                self.query_list = []
            else:
                raise ValueError("Must provide valid Robot Tag for report")
        except Exception as e:
            traceback.print_exc()
            raise e

    # ------------------------- SQL Alchemy ----------------------------
    def get_columns_from_table(self, table_name):

        query = f"""SHOW COLUMNS IN {table_name}"""
        logger.info(query)
        try:
            spark_context = SparkContext.getOrCreate()
            spark = SparkSession(spark_context)
            sql = spark.sql(query)
            print(sql)
            columns_df = sql.collect()
            cols = []
            for i in columns_df:
                cols.append(tuple(i))
            print(cols)
        except Exception as e:
            logger.error(
                "Exception - get_columns_from_table for table "
                + table_name
                + " : "
                + str(e)
            )
            self.add_result_to_report(f"""SHOW COLUMNS IN {table_name}""")
            raise e

        return cols

    # Below function to fetch no of columns from view is the same as above except here we do not use SparkContext.
    # this was done in order to get the databricks connection for the view and the table to co-exist and was not
    # possible when DBricks connect was used for spark-context
    def get_columns_from_view(self, view_name):

        query = f"""SHOW COLUMNS IN {view_name}"""
        logger.info(query)
        try:
            cols = self.session.execute(text(query)).fetchall()

        except Exception as e:
            logger.error(
                "Exception - get_columns_from_view for view "
                + view_name
                + " : "
                + str(e)
            )
            self.add_result_to_report(f"""SHOW COLUMNS IN {view_name}""")
            raise e

        return list(cols)

    def return_table_list_in_database(self, system):
        """
        Returns location on dbfs for a given table
        :return: list of tables in the database
        """
        inspector = inspect(self.engine)
        list_of_tables = []
        for table_name in inspector.get_table_names(schema=system):
            list_of_tables.append(table_name)
        return list_of_tables

    def return_column_descriptions_from_table(self, table_name, schema):

        query = f"""DESCRIBE {schema}.{table_name}"""
        logger.info(query)
        try:
            cols = self.session.execute(text(query)).fetchall()
        except Exception as e:
            logger.error(
                "Exception - return_count_multiple_columns_from_table for table "
                + table_name
                + " : "
                + str(e)
            )
            raise e

        cols = list(
            filter(
                lambda x: x[0] != "# Partitioning"
                and x[0] != "Not partitioned"
                and x[0] != "Part 0"
                and x[0] != ""
                and x[0] != "Part 1",
                cols,
            )
        )
        cols_as_dict = []
        for col in cols:
            cols_as_dict.append({"name": col[0], "type": col[1]})

        return cols_as_dict

    def return_count_of_table_with_conditions(self, table_name, condition):
        query = f"""SELECT COUNT(1) FROM {table_name}\n WHERE {condition}"""
        logger.info(query)
        try:
            count = self.session.execute(text(query)).fetchall()[0][0]
        except EOFError:
            system = table_name.split(".")[0]
            table = table_name.split(".")[1]
            count = self.run_spark_count_query(system, table)
        except Exception as e:
            logger.error(
                "Exception - return_count_of_table " + table_name + ": " + str(e)
            )
            raise e
        self.add_result_to_report(query)
        logger.info(query)
        self.add_result_to_report("Result :" + str(count) + "\n")
        return int(count)

    def return_count_of_table_with_conditions_list(
        self, table_name, source, cond1, cond2
    ):
        query = f"""SELECT COUNT(1) FROM {table_name}\nWHERE src_sys_cd =='{source}'\nAnd ({cond1}) OR({cond2})"""
        logger.info(query)
        try:
            count = self.session.execute(text(query)).fetchall()[0][0]
        except EOFError:
            system = table_name.split(".")[0]
            table = table_name.split(".")[1]
            count = self.run_spark_count_query(system, table)
        except Exception as e:
            logger.error(
                "Exception - return_count_of_table " + table_name + ": " + str(e)
            )
            raise e
        self.add_result_to_report(query)
        logger.info(query)
        self.add_result_to_report("Result :" + str(count) + "\n")
        return int(count)

    def return_count_of_table_with_dynamic_conditions(
        self, table_name, alias, myList=[]
    ):
        whitespace_columns = myList
        self.table_model = self._set_table(table_name)
        list_count = len(whitespace_columns)
        sql_list = []
        for count, column in enumerate(whitespace_columns):
            if count == list_count - 1:
                sql_list.append(
                    f"(({column} not like '% ' AND {column} not like ' %') OR {column} is Null)"
                )
            else:
                sql_list.append(
                    f"(({column} not like '% ' AND {column} not like ' %') OR {column} is Null) AND "
                )

        s3 = " \n".join(string for string in sql_list)
        s2 = f"src_sys_cd == '{alias}' AND "
        condition = s2 + s3
        query = self.session.query(self.table_model).filter(text(condition)).count()
        self.add_result_to_report(query )
        self.add_result_to_report("Result :" + str(query))
        return str(query)

    def return_count_of_whitespaces_for_table(
        self, table_name, alias, myList=[]
    ):
        whitespace_columns = myList
        self.table_model = self._set_table(table_name)
        list_count = len(whitespace_columns)
        sql_list = []
        for count, column in enumerate(whitespace_columns):
            if count == list_count - 1:
                sql_list.append(
                    f"(({column} not like '% ' AND {column} not like ' %') OR {column} is Null)"
                )
            else:
                sql_list.append(
                    f"(({column} not like '% ' AND {column} not like ' %') OR {column} is Null) AND "
                )

        s3 = " \n".join(string for string in sql_list)
        query = f"""Select res.total_with_cond,
                           res.total_per_sorce,
                           CASE
                           WHEN res.total_with_cond == res.total_per_sorce THEN TRUE
                           ELSE FALSE
                           END as result
                           from(
                           SELECT COUNT(1) as total_with_cond,(SELECT COUNT(1) FROM {table_name} Where  src_sys_cd='{alias}') as total_per_sorce
                           FROM {table_name} Where  src_sys_cd='{alias}' and {s3}) res"""
        logger.info(query)
        try:
            count = self.session.execute(text(query)).fetchall()[0][0]
            count_original = self.session.execute(text(query)).fetchall()[0][1]
            result = self.session.execute(text(query)).fetchall()[0][2]
        except EOFError:
            system = table_name.split(".")[0]
            table = table_name.split(".")[1]
            count = self.run_spark_count_query(system, table)
        except Exception as e:
            logger.error(
                "Exception - return_count_of_table " + table_name + ": " + str(e)
            )
            raise e

        self.add_result_to_report("======= Query ========")
        self.add_result_to_report(query)
        self.add_result_to_report("======= Total count per source ========")
        self.add_result_to_report(count)
        self.add_result_to_report("======= Total count per source for whitespaces ========")
        self.add_result_to_report(count_original)

        logger.info(query)
        return result

    def return_count_of_table_all_nulls(
            self, table_name, alias, myList=[]
    ):
        whitespace_columns = myList
        self.table_model = self._set_table(table_name)
        list_count = len(whitespace_columns)
        sql_list = []
        for count, column in enumerate(whitespace_columns):
            if count == list_count - 1:
                sql_list.append(
                    f"{column} is Null"
                )
            else:
                sql_list.append(
                    f"{column} is Null AND "
                )

        s3 = " \n".join(string for string in sql_list)
        query = f"""Select res.total_with_cond,
                              res.total_per_sorce,
                              CASE
                              WHEN res.total_with_cond == res.total_per_sorce THEN TRUE
                              ELSE FALSE
                              END as result
                              from(
                              SELECT COUNT(1) as total_with_cond,(SELECT COUNT(1) FROM {table_name} Where  src_sys_cd='{alias}') as total_per_sorce
                              FROM {table_name} Where  src_sys_cd='{alias}' and {s3}) res"""
        logger.info(query)
        try:
            count = self.session.execute(text(query)).fetchall()[0][0]
            count_original = self.session.execute(text(query)).fetchall()[0][1]
            result = self.session.execute(text(query)).fetchall()[0][2]
        except EOFError:
            system = table_name.split(".")[0]
            table = table_name.split(".")[1]
            count = self.run_spark_count_query(system, table)
        except Exception as e:
            logger.error(
                "Exception - return_count_of_table " + table_name + ": " + str(e)
            )
            raise e

        self.add_result_to_report("======= Query ========")
        self.add_result_to_report(query)
        self.add_result_to_report("======= Total count per source ========")
        self.add_result_to_report(count)
        self.add_result_to_report("======= Total count per source for nulls ========")
        self.add_result_to_report(count_original)

        logger.info(query)
        # self.add_result_to_report("Result :" + str(count) + "\n")
        return result

    def return_count_of_table_all_hashtags(
            self, table_name, alias, myList=[]
    ):
        whitespace_columns = myList
        self.table_model = self._set_table(table_name)
        list_count = len(whitespace_columns)
        sql_list = []
        for count, column in enumerate(whitespace_columns):
            if count == list_count - 1:
                sql_list.append(
                    f"{column} = '#' "
                )
            else:
                sql_list.append(
                    f"{column} = '#' AND "
                )

        s3 = " \n".join(string for string in sql_list)
        query = f"""Select res.total_with_cond,
                              res.total_per_sorce,
                              CASE
                              WHEN res.total_with_cond == res.total_per_sorce THEN TRUE
                              ELSE FALSE
                              END as result
                              from(
                              SELECT COUNT(1) as total_with_cond,(SELECT COUNT(1) FROM {table_name} Where  src_sys_cd='{alias}') as total_per_sorce
                              FROM {table_name} Where  src_sys_cd='{alias}' and {s3}) res"""
        logger.info(query)
        try:
            count = self.session.execute(text(query)).fetchall()[0][0]
            count_original = self.session.execute(text(query)).fetchall()[0][1]
            result = self.session.execute(text(query)).fetchall()[0][2]
        except EOFError:
            system = table_name.split(".")[0]
            table = table_name.split(".")[1]
            count = self.run_spark_count_query(system, table)
        except Exception as e:
            logger.error(
                "Exception - return_count_of_table " + table_name + ": " + str(e)
            )
            raise e

        self.add_result_to_report("======= Query ========")
        self.add_result_to_report(query)
        self.add_result_to_report("======= Total count per source ========")
        self.add_result_to_report(count)
        self.add_result_to_report("======= Total count per source for hashtags ========")
        self.add_result_to_report(count_original)

        logger.info(query)
        return result

    def return_count_of_table_all_nulls_per_column(
            self, table_name, alias,column ):

        query = f"""Select res.total_with_cond,
                              res.total_per_sorce,
                              CASE
                              WHEN res.total_with_cond == res.total_per_sorce THEN TRUE
                              ELSE FALSE
                              END as result
                              from(
                              SELECT COUNT(1) as total_with_cond,(SELECT COUNT(1) FROM {table_name} Where  src_sys_cd='{alias}') as total_per_sorce
                              FROM {table_name} Where  src_sys_cd='{alias}' and {column} is Null) res"""
        logger.info(query)
        try:
            count = self.session.execute(text(query)).fetchall()[0][0]
            count_original = self.session.execute(text(query)).fetchall()[0][1]
            result = self.session.execute(text(query)).fetchall()[0][2]
        except EOFError:
            system = table_name.split(".")[0]
            table = table_name.split(".")[1]
            count = self.run_spark_count_query(system, table)
        except Exception as e:
            logger.error(
                "Exception - return_count_of_table " + table_name + ": " + str(e)
            )
            raise e

        self.add_result_to_report("======= Query ========")
        self.add_result_to_report(query)
        self.add_result_to_report("======= Total count per source ========")
        self.add_result_to_report(count)
        self.add_result_to_report("======= Total count per source for nulls ========")
        self.add_result_to_report(count_original)

        logger.info(query)
        return result

    def return_count_of_table_all_nulls_with_condition(
           self, table_name, alias, null_filter_condition,myList=[]
        ):
            whitespace_columns = myList
            self.table_model = self._set_table(table_name)
            list_count = len(whitespace_columns)
            sql_list = []
            for count, column in enumerate(whitespace_columns):
                if count == list_count - 1:
                    sql_list.append(
                        f"{column} is Null"
                    )
                else:
                    sql_list.append(
                        f"{column} is Null AND "
                    )

            s3 = " \n".join(string for string in sql_list)
            query = f"""Select res.total_with_cond,
                                  res.total_per_sorce,
                                  CASE
                                  WHEN res.total_with_cond == res.total_per_sorce THEN TRUE
                                  ELSE FALSE
                                  END as result
                                  from(
                                  SELECT COUNT(1) as total_with_cond,(SELECT COUNT(1) FROM {table_name} Where  src_sys_cd='{alias}' and {null_filter_condition}) as total_per_sorce
                                  FROM {table_name} Where  src_sys_cd='{alias}' and {s3} and {null_filter_condition} ) res"""
            logger.info(query)
            try:
                count = self.session.execute(text(query)).fetchall()[0][0]
                count_original = self.session.execute(text(query)).fetchall()[0][1]
                result = self.session.execute(text(query)).fetchall()[0][2]
            except EOFError:
                system = table_name.split(".")[0]
                table = table_name.split(".")[1]
                count = self.run_spark_count_query(system, table)
            except Exception as e:
                logger.error(
                    "Exception - return_count_of_table " + table_name + ": " + str(e)
                )
                raise e

            self.add_result_to_report("======= Query ========")
            self.add_result_to_report(query)
            self.add_result_to_report("======= Total count per source applying null_filter_condition ========")
            self.add_result_to_report(count)
            self.add_result_to_report("======= Total count per source for nulls applying null_filter_condition ========")
            self.add_result_to_report(count_original)

            logger.info(query)
            # self.add_result_to_report("Result :" + str(count) + "\n")
            return result

    def return_count_of_table_all_pred_values(
            self, table_name, alias,column,value ):

        query = f"""Select res.total_with_cond,
                              res.total_per_sorce,
                              CASE
                              WHEN res.total_with_cond == res.total_per_sorce THEN TRUE
                              ELSE FALSE
                              END as result
                              from(
                              SELECT COUNT(1) as total_with_cond,(SELECT COUNT(1) FROM {table_name} Where  src_sys_cd='{alias}') as total_per_sorce
                              FROM {table_name} Where  {column} ={value}) res"""
        logger.info(query)
        try:
            count = self.session.execute(text(query)).fetchall()[0][0]
            count_original = self.session.execute(text(query)).fetchall()[0][1]
            result = self.session.execute(text(query)).fetchall()[0][2]
        except EOFError:
            system = table_name.split(".")[0]
            table = table_name.split(".")[1]
            count = self.run_spark_count_query(system, table)
        except Exception as e:
            logger.error(
                "Exception - return_count_of_table " + table_name + ": " + str(e)
            )
            raise e

        self.add_result_to_report("======= Query ========")
        self.add_result_to_report(query)
        self.add_result_to_report("======= Total count per source ========")
        self.add_result_to_report(count)
        self.add_result_to_report("======= Total count per source for predefined values ========")
        self.add_result_to_report(count_original)

        logger.info(query)
        return result

    def return_count_of_table_all_pred_values_or_value(
            self, table_name, alias, column, value):

        query = f"""Select res.total_with_cond,
                              res.total_per_sorce,
                              CASE
                              WHEN res.total_with_cond == res.total_per_sorce THEN TRUE
                              ELSE FALSE
                              END as result
                              from(
                              SELECT COUNT(1) as total_with_cond,(SELECT COUNT(1) FROM {table_name} Where  src_sys_cd='{alias}') as total_per_sorce
                              FROM {table_name} Where  {column} in ({value}) OR {column} is not null  And src_sys_cd='{alias}') res"""
        logger.info(query)
        try:
            count = self.session.execute(text(query)).fetchall()[0][0]
            count_original = self.session.execute(text(query)).fetchall()[0][1]
            result = self.session.execute(text(query)).fetchall()[0][2]
        except EOFError:
            system = table_name.split(".")[0]
            table = table_name.split(".")[1]
            count = self.run_spark_count_query(system, table)
        except Exception as e:
            logger.error(
                "Exception - return_count_of_table " + table_name + ": " + str(e)
            )
            raise e

        self.add_result_to_report("======= Query ========")
        self.add_result_to_report(query)
        self.add_result_to_report("======= Total count per source ========")
        self.add_result_to_report(count)
        self.add_result_to_report("======= Total count per source for predefined values or values from original table========")
        self.add_result_to_report(count_original)

        logger.info(query)
        return result

    def return_count_of_table_list_pred_values(
            self, table_name, alias, column, value):

        query = f"""Select res.total_with_cond,
                                 res.total_per_sorce,
                                 CASE
                                 WHEN res.total_with_cond == res.total_per_sorce THEN TRUE
                                 ELSE FALSE
                                 END as result
                                 from(
                                 SELECT COUNT(1) as total_with_cond,(SELECT COUNT(1) FROM {table_name} Where  src_sys_cd='{alias}') as total_per_sorce
                                 FROM {table_name} Where  {column} IN ({value})) res"""
        logger.info(query)
        try:
            count = self.session.execute(text(query)).fetchall()[0][0]
            count_original = self.session.execute(text(query)).fetchall()[0][1]
            result = self.session.execute(text(query)).fetchall()[0][2]
        except EOFError:
            system = table_name.split(".")[0]
            table = table_name.split(".")[1]
            count = self.run_spark_count_query(system, table)
        except Exception as e:
            logger.error(
                "Exception - return_count_of_table " + table_name + ": " + str(e)
            )
            raise e

        self.add_result_to_report("======= Query ========")
        self.add_result_to_report(query)
        self.add_result_to_report("======= Total count per source ========")
        self.add_result_to_report(count)
        self.add_result_to_report("======= Total count per source for predefined values ========")
        self.add_result_to_report(count_original)

        logger.info(query)
        # self.add_result_to_report("Result :" + str(count) + "\n")
        return result

    def return_count_of_table_all_hashtags_per_column(
            self, table_name, alias, column):

        query = f"""Select res.total_with_cond,
                                 res.total_per_sorce,
                                 CASE
                                 WHEN res.total_with_cond == res.total_per_sorce THEN TRUE
                                 ELSE FALSE
                                 END as result
                                 from(
                                 SELECT COUNT(1) as total_with_cond,(SELECT COUNT(1) FROM {table_name} Where  src_sys_cd='{alias}') as total_per_sorce
                                 FROM {table_name} Where  src_sys_cd='{alias}' and {column} = '#') res"""
        logger.info(query)
        try:
            count = self.session.execute(text(query)).fetchall()[0][0]
            count_original = self.session.execute(text(query)).fetchall()[0][1]
            result = self.session.execute(text(query)).fetchall()[0][2]
        except EOFError:
            system = table_name.split(".")[0]
            table = table_name.split(".")[1]
            count = self.run_spark_count_query(system, table)
        except Exception as e:
            logger.error(
                "Exception - return_count_of_table " + table_name + ": " + str(e)
            )
            raise e

        self.add_result_to_report("======= Query ========")
        self.add_result_to_report(query)
        self.add_result_to_report("======= Total count per source ========")
        self.add_result_to_report(count)
        self.add_result_to_report("======= Total count per source for hashtags ========")
        self.add_result_to_report(count_original)

        logger.info(query)
        return result

    def return_count_of_table_all_hashtags_or_value_per_column(
            self, table_name, alias, column):

        query = f"""Select res.total_without_hash,res.total_per_source, res.total_hash,
                                CASE WHEN res.total_per_source == (res.total_without_hash + res.total_hash)  THEN TRUE
                                ELSE FALSE  END as result
                                 from(
                                        Select Count(1) as total_without_hash,
                                        (Select Count(1)
                                        From {table_name}
                                        Where src_sys_cd == '{alias}' ) as total_per_source,
                                        (Select Count(1)
                                        From {table_name}
                                        Where src_sys_cd == '{alias}' and {column} = ("#") ) as total_hash
                                        From {table_name}
                                        Where {column} is not null
                                        AND {column} not in ("#")
                                        AND {column} != ('')
                                        And src_sys_cd = '{alias}') res"""
        logger.info(query)
        try:
            count_withouh_hash = self.session.execute(text(query)).fetchall()[0][0]
            count_original = self.session.execute(text(query)).fetchall()[0][1]
            count_hash = self.session.execute(text(query)).fetchall()[0][2]
            result = self.session.execute(text(query)).fetchall()[0][3]
        except EOFError:
            system = table_name.split(".")[0]
            table = table_name.split(".")[1]
            count_withouh_hash = self.run_spark_count_query(system, table)
        except Exception as e:
            logger.error(
                "Exception - return_count_of_table " + table_name + ": " + str(e)
            )
            raise e

        self.add_result_to_report("======= Query ========")
        self.add_result_to_report(query)
        self.add_result_to_report("======= Total count per source ========")
        self.add_result_to_report(count_original)
        self.add_result_to_report("======= Total count per source for hashtags ========")
        self.add_result_to_report(count_hash)
        self.add_result_to_report("======= Total count per source for values ========")
        self.add_result_to_report(count_withouh_hash)
        logger.info(query)
        return result

    def return_count_of_table_all_null_or_value_per_column(
            self, table_name, alias, column):

        query = f"""Select res.total_non_null,res.total_per_source, res.total_null,
                                CASE WHEN res.total_per_source == (res.total_non_null + res.total_null)  THEN TRUE
                                ELSE FALSE  END as result
                                 from(
                                        Select Count(1) as total_non_null,
                                        (Select Count(1)
                                        From {table_name}
                                        Where src_sys_cd == '{alias}' ) as total_per_source,
                                        (Select Count(1)
                                        From {table_name}
                                        Where src_sys_cd == '{alias}' and {column} is null ) as total_null
                                        From {table_name}
                                        Where {column} is not null
                                        AND {column} != ('')
                                        And src_sys_cd = '{alias}') res"""
        logger.info(query)
        try:
            count_withouh_hash = self.session.execute(text(query)).fetchall()[0][0]
            count_original = self.session.execute(text(query)).fetchall()[0][1]
            count_hash = self.session.execute(text(query)).fetchall()[0][2]
            result = self.session.execute(text(query)).fetchall()[0][3]
        except EOFError:
            system = table_name.split(".")[0]
            table = table_name.split(".")[1]
            count_withouh_hash = self.run_spark_count_query(system, table)
        except Exception as e:
            logger.error(
                "Exception - return_count_of_table " + table_name + ": " + str(e)
            )
            raise e

        self.add_result_to_report("======= Query ========")
        self.add_result_to_report(query)
        self.add_result_to_report("======= Total count per source ========")
        self.add_result_to_report(count_original)
        self.add_result_to_report("======= Total count per source for nulls ========")
        self.add_result_to_report(count_hash)
        self.add_result_to_report("======= Total count per source for values ========")
        self.add_result_to_report(count_withouh_hash)
        logger.info(query)
        return result

    def return_count_of_table_whitespaces_per_column(
            self, table_name, alias,column ):

        query = f"""Select res.total_with_cond,
                              res.total_per_sorce,
                              CASE
                              WHEN res.total_with_cond == res.total_per_sorce THEN TRUE
                              ELSE FALSE
                              END as result
                              from(
                              SELECT COUNT(1) as total_with_cond,(SELECT COUNT(1) FROM {table_name} Where  src_sys_cd='{alias}') as total_per_sorce
                              FROM {table_name} Where  src_sys_cd='{alias}' AND ({column} not like '% ' AND {column} not like ' %' OR {column} is Null) ) res"""
        logger.info(query)
        try:
            count = self.session.execute(text(query)).fetchall()[0][0]
            count_original = self.session.execute(text(query)).fetchall()[0][1]
            result = self.session.execute(text(query)).fetchall()[0][2]
        except EOFError:
            system = table_name.split(".")[0]
            table = table_name.split(".")[1]
            count = self.run_spark_count_query(system, table)
        except Exception as e:
            logger.error(
                "Exception - return_count_of_table " + table_name + ": " + str(e)
            )
            raise e

        self.add_result_to_report("======= Query ========")
        self.add_result_to_report(query)
        self.add_result_to_report("======= Total count per source ========")
        self.add_result_to_report(count)
        self.add_result_to_report("======= Total count per source for whetespaces ========")
        self.add_result_to_report(count_original)

        logger.info(query)
        # self.add_result_to_report("Result :" + str(count) + "\n")
        return result

    def return_count_of_table_null_column_check_with_conditions(
        self, table_name, alias, myList=[]
    ):
        null_columns_list = myList
        self.table_model = self._set_table(table_name)
        list_count = len(null_columns_list)
        sql_list = []
        for count, column in enumerate(null_columns_list):
            if count == list_count - 1:
                sql_list.append(f"({column}  IS NULL)")
            else:
                sql_list.append(f"({column} IS NULL) AND ")

        s3 = " \n".join(string for string in sql_list)
        s2 = f"src_sys_cd == '{alias}' AND "
        condition = s2 + s3
        query = self.session.query(self.table_model).filter(text(condition)).count()
        self.add_result_to_report(query)
        self.add_result_to_report("Result :" + str(query))
        return str(query)

    # ------------------------- SQL Query ----------------------------
    def return_location_of_table_on_dbfs(self, table_name, schema):
        """
        Returns location on dbfs for a given table
        :param schema: name of the schema
        :param table_name: name of table
        :return: location of table on dbfs
        """
        location_on_dbfs = ""
        query = text(f"DESCRIBE EXTENDED {schema}.{table_name}")
        self.add_result_to_report(query)
        for row in self.session.execute(query):
            row_as_dict = dict(row)
            if row_as_dict["col_name"] == "Location":
                location_on_dbfs = row_as_dict["data_type"]
                print("*****",location_on_dbfs)
        return location_on_dbfs

    def return_primary_check(self, table_name, column_list):
        query = f"""SELECT {column_list}, count(1) as cnt \n FROM {table_name} \n group by {column_list} \n having count(1) > 1 \n Limit 10"""
        try:
            result = self.session.execute(query).fetchall()
        except Exception as e:
            logger.error("Exception occurred {run_sql_query_full_with_cond_for_views}: " + str(e))
            return 1
        self.add_result_to_report("=====Query that checks Uniqueness Of The Primary Keys=====\n ")
        self.add_result_to_report(query)
        for row in result:
            self.add_result_to_report(str(row))

        return result

    def return_count_of_table(self, table_name):
        """
        Returns a count of records in a table
        :param table_name:  table name passed from robot keyword #NB Must be in the format SCHEMA_NAME.TABLE_NAME
        :return:  Count of query objects (int)
        """
        query = f"""SELECT COUNT(1) FROM {table_name}"""
        logger.info(query)
        try:
            count = self.session.execute(text(query)).fetchall()[0][0]
        except EOFError:
            system = table_name.split(".")[0]
            table = table_name.split(".")[1]
            count = self.run_spark_count_query(system, table)
        except Exception as e:
            logger.error(
                "Exception - return_count_of_table " + table_name + ": " + str(e)
            )
            raise e
        self.add_result_to_report(query)
        logger.info(query)
        self.add_result_to_report("Result :" + str(count) + "\n")
        return int(count)

    def return_count_of_table_with_nulls(self, table_name, source, myList=[]):
        nulls_columns = myList
        self.table_model = self._set_table(table_name)
        list_count = len(nulls_columns)
        sql_list = []
        for count, column in enumerate(nulls_columns):
            if count == list_count - 1:
                sql_list.append(f"{column} is Null")
            else:
                sql_list.append(f"{column} is Null OR ")

        condition = " \n".join(string for string in sql_list)
        query = f"""SELECT COUNT(1) \n FROM {table_name} \n WHERE {condition} \nAnd SRC_SYS_CD='{source}'"""
        logger.info(query)
        try:
            count = self.session.execute(text(query)).fetchall()[0][0]
        except:
            spark_context = SparkContext.getOrCreate()
            spark = SparkSession(spark_context)
            sql = spark.sql(query)
            count_row = sql.collect()
            count = count_row[0].KEY_COUNT
        self.add_result_to_report("\n=====Query to check null columns=====\n")
        self.add_result_to_report(query)
        self.add_result_to_report("Result :" + str(count) + "\n")

        return int(count)

    def return_count_of_table_with_nulls_UTCS(self, table_name, source, myList=[]):
        nulls_columns = myList
        self.table_model = self._set_table(table_name)
        list_count = len(nulls_columns)
        sql_list = []
        for count, column in enumerate(nulls_columns):
            if count == list_count - 1:
                sql_list.append(f"{column} is Null")
            else:
                sql_list.append(f"{column} is Null OR ")

        condition = " \n".join(string for string in sql_list)
        query = f"""Select res.total_with_cond,
                                 res.total_per_sorce,
                                 CASE
                                 WHEN res.total_with_cond == res.total_per_sorce THEN TRUE
                                 ELSE FALSE
                                 END as result
                                 from(
                                 SELECT COUNT(1) as total_with_cond,(SELECT COUNT(1) FROM {table_name} Where  src_sys_cd='{source}') as total_per_sorce
                                 FROM {table_name}  WHERE {condition} \nAnd SRC_SYS_CD='{source}' ) res"""
        logger.info(query)
        logger.info(query)
        try:
            result = self.session.execute(text(query)).fetchall()[0][2]
        except EOFError:
            system = table_name.split(".")[0]
            table = table_name.split(".")[1]
        except Exception as e:
            logger.error(
                "Exception - return_count_of_table " + table_name + ": " + str(e)
            )
            raise e
        logger.info(query)
        return result

    def return_count_of_table_with_not_nulls(self, table_name,source, myList=[]):
        nulls_columns = myList
        self.table_model = self._set_table(table_name)
        list_count = len(nulls_columns)
        sql_list = []
        for count, column in enumerate(nulls_columns):
            if count == list_count - 1:
                sql_list.append(f"{column} is not Null")
            else:
                sql_list.append(f"{column} is not Null OR ")

        condition = " \n".join(string for string in sql_list)
        query = f"""SELECT COUNT(1) \n FROM {table_name} \n WHERE  SRC_SYS_CD='{source}' and {condition}"""
        logger.info(query)
        try:
            count = self.session.execute(text(query)).fetchall()[0][0]
        except:
            spark_context = SparkContext.getOrCreate()
            spark = SparkSession(spark_context)
            sql = spark.sql(query)
            count_row = sql.collect()
            count = count_row[0].KEY_COUNT
        self.add_result_to_report("\n=====Query to check not null columns=====\n")
        self.add_result_to_report(query)
        self.add_result_to_report("Result :" + str(count) + "\n")

        return int(count)

    def return_count_of_table_not_null(self, table_name, column):
        query = f"""SELECT COUNT(1) FROM {table_name} WHERE {column} IS NOT NULL """
        logger.info(query)
        try:
            count = self.session.execute(text(query)).fetchall()[0][0]
        except EOFError:
            system = table_name.split(".")[0]
            table = table_name.split(".")[1]
            count = self.run_spark_count_query(system, table)
        except Exception as e:
            logger.error(
                "Exception - return_count_of_table " + table_name + ": " + str(e)
            )
            raise e
        self.add_result_to_report(query)
        logger.info(query)
        self.add_result_to_report("Result :" + str(count) + "\n")
        return int(count)

    def return_count_of_table_is_null_per_col(self, target,source, column):
        query = f"""SELECT COUNT(1) FROM {target} WHERE {column} IS NULL and SRC_SYS_CD='{source}' """
        logger.info(query)
        try:
            count = self.session.execute(text(query)).fetchall()[0][0]
        except EOFError:
            count = self.run_spark_count_query({target})
        except Exception as e:
            logger.error(
                "Exception - return_count_of_table " +  {target}  + ": " + str(e)
            )
            raise e
        self.add_result_to_report("\n=====Query to check nulls=====\n")
        self.add_result_to_report(query)
        logger.info(query)
        self.add_result_to_report("Result :" + str(count) + "\n")
        return int(count)

    def return_count_of_table_is_not_null_per_col(self, target,source, column):
        query = f"""SELECT COUNT(1) FROM {target} WHERE {column} IS NOT NULL and SRC_SYS_CD='{source}'  """
        logger.info(query)
        try:
            count = self.session.execute(text(query)).fetchall()[0][0]
        except EOFError:
            count = self.run_spark_count_query( {target})
        except Exception as e:
            logger.error(
                "Exception - return_count_of_table " +  {target} + ": " + str(e)
            )
            raise e
        logger.info(query)
        return int(count)

    def return_count_column_null(self, table_name, column):
        query = f"""SELECT COUNT(1) FROM {table_name} WHERE {column} IS NULL """
        logger.info(query)
        try:
            count = self.session.execute(text(query)).fetchall()[0][0]
        except EOFError:
            system = table_name.split(".")[0]
            table = table_name.split(".")[1]
            count = self.run_spark_count_query(system, table)
        except Exception as e:
            logger.error(
                "Exception - return_count_of_table " + table_name + ": " + str(e)
            )
            raise e
        self.add_result_to_report("\n=====Query to check nulls=====\n")
        self.add_result_to_report(query)
        logger.info(query)
        self.add_result_to_report("Result :" + str(count) + "\n")
        return int(count)

    def return_count_column_null_source(self, table_name, column,source):
        query = f"""SELECT COUNT(1) FROM {table_name} WHERE {column} IS NULL And SRC_SYS_CD='{source}' """
        logger.info(query)
        try:
            count = self.session.execute(text(query)).fetchall()[0][0]
        except EOFError:
            system = table_name.split(".")[0]
            table = table_name.split(".")[1]
            count = self.run_spark_count_query(system, table)
        except Exception as e:
            logger.error(
                "Exception - return_count_of_table " + table_name + ": " + str(e)
            )
            raise e
        self.add_result_to_report("\n=====Query to check nulls=====\n")
        self.add_result_to_report(query)
        logger.info(query)
        self.add_result_to_report("Result :" + str(count) + "\n")
        return int(count)

    def add_system_information_to_report_null(self, table_name, system_source):

        self.add_result_to_report(
            f""" \n=====Validation of {table_name} for the {system_source} source system that specified columns contains all nulls===== """
        )

    def add_system_information_to_predefined_report_columns(
        self, table_name, system_source, column, value
    ):

        self.add_result_to_report(
            f""" \n=====Validation of {table_name} for the {system_source} source system that {column} column contains all {value} values====="""
        )

    def add_system_information_to_report_hashtag(self, table_name, system_source):

        self.add_result_to_report(
            f"""\n=====Validation of {table_name} for the {system_source} source system that specified columns contains hashtag values====="""
        )

    def add_system_information_to_report_whitespaces(self, table_name, system_source):

        self.add_result_to_report(
            f"""\n=====Validation of {table_name} for the {system_source} source system that trim has been applied to specified columns===== """
        )

    def add_columns_names_to_report(self, column_names):

        self.add_result_to_report(f"""| {column_names}""")

    def return_count_multiple_columns_from_table(self, table_name, column_names):
        """
        :type column_names: list of columns that are returned from query
        :param table_name:  table name passed from robot keyword #NB Must be in the format SCHEMA_NAME.TABLE_NAME
        :return:  amount of records returned from query
        """
        query = f"""SELECT COUNT(1) AS KEY_COUNT FROM (SELECT DISTINCT {column_names} FROM {table_name})"""
        logger.info(query)
        try:
            count = self.session.execute(text(query)).fetchall()[0][0]
        except:
            spark_context = SparkContext.getOrCreate()
            spark = SparkSession(spark_context)
            sql = spark.sql(query)
            count_row = sql.collect()
            count = count_row[0].KEY_COUNT

        self.add_result_to_report(
            f"""SELECT COUNT(1) \nFROM (SELECT DISTINCT {column_names} \n\tFROM {table_name})"""
        )
        self.add_result_to_report("Result :" + str(count) + "\n")

        return int(count)

    def return_count_of_table_version_zero(self, table_name):
        """
        Returns a count of records in a table
        :param table_name:  table name passed from robot keyword #NB Must be in the format SCHEMA_NAME.TABLE_NAME
        :return:  Count of query objects (int) from version 0
        """
        query = f"""SELECT COUNT(1) FROM {table_name} VERSION AS OF 0"""
        try:
            count = self.session.execute(text(query)).fetchall()[0][0]
        except EOFError as eof:
            logger.error(
                "EOFError - return_count_of_table_version_zero for table "
                + table_name
                + " : "
                + str(eof)
            )
            system = table_name.split(".")[0]
            table = table_name.split(".")[1]
            count = self.run_spark_count_version_zero(system, table)

        except Exception as e:
            logger.error(
                "Exception - return_count_of_table_version_zero for table "
                + table_name
                + " : "
                + str(e)
            )
            raise e

        self.add_result_to_report(
            f"""SELECT COUNT(1) \nFROM {table_name} VERSION AS OF 0"""
        )
        return int(count)

    def run_source_target_comparison_query(self, table, col_names, system):
        """
        Compares the difference in counts between the source(_stg) and target folder.
        :param table: the table under test
        :param col_names: the columns under test
        :param system: the system under test
        :return: an integer representation of the difference in count between source and target
        """
        try:
            # This will have an impact if we're doing joins. The spark default is 4gb (4294967296)
            # In this case, it prevents the driver OOM conditions such as:
            # java.util.concurrent.ExecutionException:org.apache.spark.sql.execution.OutOfMemorySparkException:
            #          Size of broadcasted table far exceeds estimates and exceeds limit of spark.driver.maxResultSize=4294967296.
            #          You can disable broadcasts for this query using set spark.sql.autoBroadcastJoinThreshold=-1
            self.session.execute(text("SET spark.sql.autoBroadcastJoinThreshold=-1"))

            count = self.session.execute(
                text(
                    f"""SELECT COUNT(1) from (Select {col_names} from {system}_STG2.{table} MINUS Select {col_names} from {system}.{table} VERSION AS OF 0)"""
                )
            ).fetchall()[0][0]
        except EOFError as e:
            logger.error(
                f"EOFError occurred in run_source_target_comparison_query for : {table}: "
                + str(e)
            )
            return -1
        except Exception as e:
            logger.error(
                f"Exception occurred in run_source_target_comparison_query for {table}: "
                + str(e)
            )
            return -1

        self.add_result_to_report(
            f"""SELECT COUNT(1) \nfrom (Select {col_names} \n\tfrom {system}_STG2.{table} \nMINUS Select {col_names} \nfrom {system}.{table} VERSION AS OF 0)"""
        )

        if not isinstance(count, int):
            logger.error(f"ERROR: Result is not an integer: {count}")
            return -1

        return int(count)

    def run_count_query_with_condition(self, table, column, system, condition):
        """
        Run a count query on a table with a given condition
        :param table: the table under test
        :param system: the system under test
        :param column: the column to count
        :param condition: the condition to check
        :return: a count of rows returned from the query
        """
        query = f"""Select count({column}) from {system}.{table} where {column} {condition}"""

        try:
            count = self.session.execute(text(query)).fetchall()[0][0]
        except EOFError as e:
            logger.error(
                "EOF ERROR occurred in run_count_query_with_condition: " + str(e)
            )
            count = self.run_spark_comparison_query(system, table, column)
        except Exception as e:
            logger.error(
                f"Exception occurred in run_count_query_with_condition for {table}: "
                + str(e)
            )
            count = self.run_spark_comparison_query(system, table, column)

        self.add_result_to_report(query)
        self.add_result_to_report("Result :" + str(count))
        return int(count)

    def run_count_query_with_conditions(self, table, system, condition):
        """
        Run a count query on a table with a given condition
        :param table: the table under test
        :param system: the system under test
        :param condition: the condition to check
        :return: a count of rows returned from the query
        """
        query = f"""Select count(1) from {system}.{table} where {condition}"""
        try:
            count = self.session.execute(text(query)).fetchall()[0][0]
        except EOFError as e:
            logger.error(
                "EOF ERROR occurred in run_count_query_with_conditions: " + str(e)
            )
            raise e

        except Exception as e:
            logger.error(
                f"Exception occurred in run_count_query_with_conditions for {table}: "
                + str(e)
            )
            raise e

        self.add_result_to_report(query)
        self.add_result_to_report("Result :" + str(count))
        return int(count)

    def run_distinct_query_with_condition(self, table, column, system, condition):
        """
        Run a distinct query on a table with a given condition
        :param table: the table under test
        :param system: the system under test
        :param column: the column to count
        :param condition: the condition to check
        :return: a count of rows returned from the query
        """
        try:
            query = f"""Select distinct({column}) from {system}.{table} where {column} {condition}"""
            distinct_result = self.session.execute(text(query)).fetchall()[0][0]
        except EOFError as e:
            logger.error(
                "EOF ERROR occurred in run_distinct_query_with_condition: " + str(e)
            )
            raise e

            # count = self.run_spark_comparison_query(system, table, column)
        except Exception as e:
            logger.console(
                "Exception occurred in run_distinct_query_with_condition: " + str(e)
            )
            raise e

        self.add_result_to_report(query)
        self.add_result_to_report("Result :" + str(distinct_result))

        return distinct_result

    def return_datatype_of_column(self, system, table, column):
        try:
            query = f"""describe {system}.{table} {column}"""
            distinct_result = self.session.execute(text(query)).fetchall()[1][1]
        except EOFError as e:
            logger.error("EOF ERROR occurred in return_datatype_of_column: " + str(e))
            raise e

        except Exception as e:
            logger.console("Exception occurred in return_datatype_of_column: " + str(e))
            raise e

        self.add_result_to_report(query)
        self.add_result_to_report("Result :" + str(distinct_result))
        return distinct_result

    def return_date_as_utc(self, system, table, column):
        """
        Runs a query to return a datetime in UTC format
        :param table: the table under test
        :param system: the system under test
        :param column: the column to return as utc
        :return: a utc format string
        """
        self.add_result_to_report("\n=====Query to check Follow UTC=====\n")
        query = f"""SELECT date_format((SELECT {column} \n FROM {system}.{table} \n WHERE {column} IS NOT NULL limit 1),"yyyy-MM-dd'T'HH:mm:ss.SSSZ")"""
        self.add_result_to_report(query)

        try:
            utc_date = self.session.execute(text(query)).fetchall()[0][0]
        except EOFError as e:
            logger.error("EOFERROR occurred in return_datatype_of_column: " + str(e))
            return "NO utc date retrieved"
        except Exception as e:
            logger.error("Exception occurred in return_datatype_of_column: " + str(e))
            return "NO utc date retrieved"
        self.add_result_to_report("Result :" + str(utc_date))
        return utc_date

    def return_date_as_utc_source(self, system, table, column, alias):
        """
        Runs a query to return a datetime in UTC format
        :param table: the table under test
        :param system: the system under test
        :param column: the column to return as utc
        :return: a utc format string
        """
        self.add_result_to_report("\n=====Query to check UTC format=====\n")

        query = f"""SELECT date_format((select {column} from {system}.{table} where {column} is not null And SRC_SYS_CD='{alias}' limit 1),"yyyy-MM-dd'T'HH:mm:ss.SSSZ")"""
        self.add_result_to_report(query)

        try:
            utc_date = self.session.execute(text(query)).fetchall()[0][0]
        except EOFError as e:
            logger.error("EOFERROR occurred in return_datatype_of_column: " + str(e))
            return "NO utc date retrieved"
        except Exception as e:
            logger.error("Exception occurred in return_datatype_of_column: " + str(e))
            return "NO utc date retrieved"
        return utc_date

    def count_non_nulls(self, system, table, column):
        query = f"""SELECT COUNT(1) from {system}.{table} where {column} is not null """
        try:
            non_nulls = self.session.execute(query).fetchall()[0][0]
            self.add_result_to_report(query)
            return non_nulls
        except Exception as e:
            logger.error("Exception occurred {count_non_nulls}: " + str(e))
        return 0

    def test_data_count_per_source(self, system, table, source):
        query = (
            f"""SELECT COUNT(1) from {system}.{table} where SRC_SYS_CD='{source}' """
        )
        try:
            trw_data_count = self.session.execute(query).fetchall()[0][0]
            self.add_result_to_report(query)
            return trw_data_count
        except Exception as e:
            logger.error("Exception occurred {trw_data_count}: " + str(e))
        return 0

    def check_src_sys_active_flag(self, system, table):
        """
        Runs a query to check Active flag for src_sys
        :param table: the table under test
        :param system: the system under test
        :return: count of flags not set
        """
        try:
            count = self.session.execute(
                text(
                    f"""SELECT COUNT(1) from (select * from {system}.{table} where SRC_SYS_SHRT_NM  in ('SUSTAIN','E2','ATLAS','PANDA','elims') AND Active <>1)"""
                )
            ).fetchall()[0][0]
        except EOFError as e:
            logger.console("EOF ERROR occurred in check_src_sys_active_flag ")
            raise e

        except Exception as e:
            logger.console("Exception occurred in check_src_sys_active_flag")
            raise e

        self.add_result_to_report(
            f"""SELECT COUNT(1) from (select * from {system}.{table} where SRC_SYS_SHRT_NM  in ('Sustain','E2','ATLAS','Panda','eLIMS') AND Active <>1)"""
        )
        self.add_result_to_report("Result : " + str(count))

        return True if count == 0 else False

    def run_sql_query(self, query):
        query = f"""{query}"""
        try:
            result = self.session.execute(query).fetchall()[0][0]
        except Exception as e:
            logger.error("Exception occurred {run_sql_query}: " + str(e))
            return 1

        self.add_result_to_report(query)
        self.add_result_to_report("Actual result : " + str(result))

        return result

    def run_sql_query_full(self, query):
        query = f"""{query}"""
        try:
            result = self.session.execute(query).fetchall()
        except Exception as e:
            logger.error("Exception occurred {run_sql_query_full}: " + str(e))
            return 1

        self.add_result_to_report(query)
        self.add_result_to_report("Actual result : ")
        for row in result:
            self.add_result_to_report(str(row))
        return result

    def run_rule_query_full(self, selectcond, rule, var):
        query = f"""{selectcond} {rule}\n AND {var}"""
        try:
            result = self.session.execute(query).fetchall()
        except Exception as e:
            logger.error("Exception occurred {run_sql_query_full}: " + str(e))
            return 1

        return result

    def run_sql_query_to_get_value_from_column(self, column, table, sqlConditon):
        query = f"""Select {column}\nFrom l1.{table}\n {sqlConditon}"""
        try:
            result = self.session.execute(query).fetchall()

        except Exception as e:
            logger.error("Exception occurred {run_sql_query_full}: " + str(e))
            return 1

        self.add_result_to_report("For table:" + table)

        return result

    def run_sql_query_to_get_value_from_view_column(
        self, column, system, table, sqlConditon
    ):
        query = f"""Select {column}\nFrom {system}.{table}\n {sqlConditon}"""
        try:
            result = self.session.execute(query).fetchall()

        except Exception as e:
            logger.error("Exception occurred {run_sql_query_full}: " + str(e))
            return 1

        return result

    def run_sql_query_full_with_cond(self, query, var):
        query = f"""{query} {var}"""
        try:
            result = self.session.execute(query).fetchall()
        except Exception as e:
            logger.error("Exception occurred {run_sql_query_full_with_cond}: " + str(e))
            return 1

        self.add_result_to_report(query)
        self.add_result_to_report("Actual result : ")
        for row in result:
            self.add_result_to_report(str(row))
        return result

    def run_sql_query_full_with_cond_for_views(self, system, view, var):
        query = f"""SELECT * \n   FROM  {system}.{view}\n {var}"""
        try:
            result = self.session.execute(query).fetchall()
        except Exception as e:
            logger.error(
                "Exception occurred {run_sql_query_full_with_cond_for_views}: " + str(e)
            )
            return 1

        self.add_result_to_report(query)
        self.add_result_to_report("Actual result : ")
        for row in result:
            self.add_result_to_report(str(row))
        return result

    def run_sql_query_with_select_cond_for_views(
        self, column, system, view, cond1, cond2
    ):
        query = f"""SELECT {column} \n   FROM  {system}.{view}\n Where {cond1}  And   {cond2} """
        try:
            result = self.session.execute(query).fetchall()
        except Exception as e:
            logger.error(
                "Exception occurred {run_sql_query_with_select_cond_for_views}: "
                + str(e)
            )
            return 1

        self.add_result_to_report(query)
        self.add_result_to_report("Actual result : ")
        for row in result:
            self.add_result_to_report(str(row))
        return result

    def run_sql_query_full_for_2_unions(
        self,
        select_distinct,
        union1,
        union_from_cond_1,
        where_cond_1,
        union2,
        union_from_cond_2,
        where_cond_2,
        var,
    ):
        query = f"""{select_distinct},{union1}\n{union_from_cond_1}\n{where_cond_1}\n {var}  \n UNION ALL\n
        {select_distinct},{union2} \n{union_from_cond_2}\n{where_cond_2}\n{var} \n  {var}"""
        try:
            result = self.session.execute(query).fetchall()
        except Exception as e:
            logger.error(
                "Exception occurred {run_sql_query_full_for_2_unions}: " + str(e)
            )
            return 1
        self.add_result_to_report(query)
        for row in result:
            self.add_result_to_report(str(row))
        return result

    def run_sql_query_for_null_check_views(self, column, system, view, cond1):
        query = f"""SELECT {column} \n  FROM {system}.{view}\n Where {cond1} Limit 1"""
        try:
            result = self.session.execute(query).fetchall()
        except Exception as e:
            logger.error(
                "Exception occurred {run_sql_query_for_null_check_views}: " + str(e)
            )
            return 1

        self.add_result_to_report(query)
        self.add_result_to_report("Actual result : ")
        for row in result:
            self.add_result_to_report(str(row))
        return result

    def run_sql_query_for_count_null_check_views(self, column, system, view, cond1):
        query = f"""SELECT COUNT(1) {column} from {system}.{view}\n Where {cond1}"""
        try:
            result = self.session.execute(query).fetchall()
        except Exception as e:
            logger.error(
                "Exception occurred {run_sql_query_for_null_check_views}: " + str(e)
            )
            return 1

        self.add_result_to_report(query)
        self.add_result_to_report("Actual result : ")
        for row in result:
            self.add_result_to_report(str(row))
        return result

    def run_sql_query_for_count_null_check_views_column(
        self, column, system, view, cond1
    ):
        query = f"""SELECT COUNT(1)  from {system}.{view}\n Where {column} is null And {cond1}"""
        try:
            result = self.session.execute(query).fetchall()
        except Exception as e:
            logger.error(
                "Exception occurred {run_sql_query_for_null_check_views}: " + str(e)
            )
            return 1
        self.add_result_to_report(query)
        self.add_result_to_report("Actual result : ")
        for row in result:
            self.add_result_to_report(str(row))
        return result

    def run_sql_query_full_for_3_unions(
        self,
        select_distinct,
        union1,
        union_from_cond_1,
        where_cond_1,
        union2,
        union_from_cond_2,
        where_cond_2,
        union3,
        union_from_cond_3,
        where_cond_3,
        var,
    ):
        query = f"""{select_distinct},{union1}\n{union_from_cond_1}\n{where_cond_1}\n {var}  \n UNION ALL\n
        {select_distinct},{union2} \n{union_from_cond_2}\n{where_cond_2}\n{var} \n UNION ALL\n{select_distinct},{union3}\n{union_from_cond_3}\n{where_cond_3}\n {var}"""
        try:
            result = self.session.execute(query).fetchall()
        except Exception as e:
            logger.error(
                "Exception occurred {run_sql_query_full_for_unions}: " + str(e)
            )
            return 1

        self.add_result_to_report(query)
        for row in result:
            self.add_result_to_report(str(row))
        return result

    def run_sql_query_full_for_4_unions(
        self,
        select_distinct,
        union1,
        union_from_cond_1,
        where_cond_1,
        union2,
        union_from_cond_2,
        where_cond_2,
        union3,
        union_from_cond_3,
        where_cond_3,
        union4,
        union_from_cond_4,
        where_cond_4,
        var,
        varunion4,
    ):
        query = f"""{select_distinct},{union1}\n{union_from_cond_1}\n{where_cond_1}\n {var}  \n UNION ALL\n
        {select_distinct},{union2} \n{union_from_cond_2}\n{where_cond_2}\n{var} \n UNION ALL\n{select_distinct},{union3}\n{union_from_cond_3}\n{where_cond_3}\n{var}\n
        UNION ALL\n{select_distinct},{union4}\n{union_from_cond_4}\n{where_cond_4}\n{varunion4}"""
        try:
            result = self.session.execute(query).fetchall()
        except Exception as e:
            logger.error(
                "Exception occurred {run_sql_query_full_for_unions}: " + str(e)
            )
            return 1

        self.add_result_to_report(query)
        for row in result:
            self.add_result_to_report(str(row))
        return result

    def run_sql_query_for_unions_with_rule(self, select, system, view, column):
        query = f"""SELECT {select}\nFrom {system}.{view}\nWhere {column} is null\n Limit 1"""
        try:
            result = self.session.execute(query).fetchall()
        except Exception as e:
            logger.error(
                "Exception occurred {run_sql_query_full_for_unions}: " + str(e)
            )
            return 1
        return result

    def run_sql_query_for_unions_with_rule_cond(self, select, system, view, column):
        query = f"""SELECT {select}\nFrom {system}.{view}\nWhere {column}\n Limit 1"""
        try:
            result = self.session.execute(query).fetchall()
        except Exception as e:
            logger.error(
                "Exception occurred {run_sql_query_full_for_unions}: " + str(e)
            )
            return 1
        self.add_result_to_report(query)
        self.add_result_to_report("Final column data: ")
        for row in result:
            self.add_result_to_report(str(row))
        return result

    def run_sql_query_cond_for_unions(
        self, column, union_from_cond_1, where_cond_1, cond1, cond2
    ):
        query = f"""Select {column}\n{union_from_cond_1}\n{where_cond_1}\n And {cond1} \nAnd {cond2}  """
        try:
            result = self.session.execute(query).fetchall()
        except Exception as e:
            logger.error(
                "Exception occurred {run_sql_query_cond_for_unions}: " + str(e)
            )
            return 1

        self.add_result_to_report(query)
        for row in result:
            self.add_result_to_report(str(row))
        return result

    def check_for_null_in_columns(self, table, column_list):

        query = "Select * from " + table + " where "
        for i in range(len(column_list)):
            if i == 0:
                query = query + column_list[i] + " is null "
            else:
                query = query + "or " + column_list[i] + " is null "
        try:
            spark_context = SparkContext.getOrCreate()
            spark = SparkSession(spark_context)
            print(query)
            sql = spark.sql(query)
            count_row = sql.collect()
            count = len(count_row)
        except Exception as e:
            logger.info(e)
            logger.error(
                "Exception - return_count_multiple_columns_from_table for table "
                + table
                + " : "
                + str(e)
            )
            raise e

        self.add_result_to_report(f"""{query}""")
        return int(count)

    def run_sql_query_full_with_cond(self, query, var):
        query = f"""{query} {var}"""
        try:
            result = self.session.execute(query).fetchall()
        except Exception as e:
            logger.error("Exception occurred {run_sql_query_full}: " + str(e))
            return 1

        self.add_result_to_report(query)
        self.add_result_to_report("|Actual result : ")
        for row in result:
            self.add_result_to_report(str(row))
        return result

    def run_get_data_from_original_table(self, query, var):
        query = f"""Select {query} {var} limit 1"""
        try:
            result = self.session.execute(query).fetchall()
        except Exception as e:
            logger.error("Exception occurred {run_sql_query_full}: " + str(e))
            return 1

        return result

    def run_get_data_from_original_table_with_cond(self, query, join, cond):
        query = f"""Select {query} {join} Where {cond}"""
        try:
            result = self.session.execute(query).fetchall()
        except Exception as e:
            logger.error("Exception occurred {run_sql_query_full}: " + str(e))
            return 1

        self.add_result_to_report(query)
        return result

    def run_get_data_from_final_table(self, columns, table, var):
        query = f"""Select  {columns}  From {table}    Where {var} """
        try:
            result = self.session.execute(query).fetchall()
        except Exception as e:
            logger.error("Exception occurred {run_sql_query_full}: " + str(e))
            return 1

        self.add_result_to_report(query)
        return result

    @staticmethod
    def check_for_count_of_characters_in_column(table, column, expected):

        query = f"""select * from ( select length({column}||"+0000") as `utc_format` from {table} where {column} is not null ) where utc_format <> {expected}"""
        try:
            spark_context = SparkContext.getOrCreate()
            spark = SparkSession(spark_context)
            print(query)
            sql = spark.sql(query)
            count_row = sql.collect()
            count = len(count_row)
        except Exception as e:
            logger.info(e)
            logger.error(
                "Exception - return_count_multiple_columns_from_table for table "
                + table
                + " : "
                + str(e)
            )
            raise e

        return int(count)